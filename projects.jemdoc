# jemdoc: menu{MENU}{projects.html}
== Shengjun(Daniel) Zhang - Projects

== Recent Projects 
- *Nonlinear System Identification via Sparse Bayesian Learning.*
~~~
{}{img_left}{pendulum.png}{Photo}{200}{200}
In this project, I mainly reimplemented the /Sparase Bayesian Learning Algorithm/, proposed in \[[https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7094238 /A Sparse Bayesian Approach to The Identification of Nonlinear State-space Systems/]] and applied it to identify a pendulum model, also, I used a deep learning approach to verify the results.
~~~

- *Applying Q-Learning to a 4 $\times$ 4 Tic-Tac-Toe. \[[https://github.com/ShengjunZhang/EENG-5940-Q-Learning_TicTacToe/ Code]] \[[https://youtu.be/vwLyn7iPNuA Demo]]*
~~~
{}{img_left}{ttt.png}{Photo}{200}{200}
Reinforcement learning is essential for applications where there is no single correct way to solve a problem. In this project, I show that reinforcement learning is very effective at learning how to play the game Tic-Tac-Toe, despite the high-dimensional state. The agent is not given information about what the blocks or grids look like - it must learn these representations and directly use the reward and Q-values to develop an optimal strategy. The Q-agent uses basic Q-Learning algorithm, and shows that it is able to achieve super-human performance.
~~~
